{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparkPipelinePractice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJJS5hxQWlos",
        "outputId": "f76f5fd0-2827-4d48-d00b-233edee72d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 66.3 kB/88.7 kB 75%] [Connec\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [1 InRelease 7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [3 In\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/15.9 k\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,094 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,072 kB]\n",
            "Fetched 3,434 kB in 3s (1,311 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.3.0'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Yelp_NLP\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "K_sw6DMkWryA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_16/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO0iaPfHWvvH",
        "outputId": "3455c1fc-c6fa-42cd-90ee-7b02416edff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|   class|                text|\n",
            "+--------+--------------------+\n",
            "|positive|Wow... Loved this...|\n",
            "|negative|  Crust is not good.|\n",
            "|negative|Not tasty and the...|\n",
            "|positive|Stopped by during...|\n",
            "|positive|The selection on ...|\n",
            "|negative|Now I am getting ...|\n",
            "|negative|Honeslty it didn'...|\n",
            "|negative|The potatoes were...|\n",
            "|positive|The fries were gr...|\n",
            "|positive|      A great touch.|\n",
            "|positive|Service was very ...|\n",
            "|negative|  Would not go back.|\n",
            "|negative|The cashier had n...|\n",
            "|positive|I tried the Cape ...|\n",
            "|negative|I was disgusted b...|\n",
            "|negative|I was shocked bec...|\n",
            "|positive| Highly recommended.|\n",
            "|negative|Waitress was a li...|\n",
            "|negative|This place is not...|\n",
            "|negative|did not like at all.|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "metadata": {
        "id": "LbWl8oGcW1YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "#create a length column to be used for a future feature\n",
        "dataDF = df.withColumn('length', length(df['text']))\n",
        "dataDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVIFkjybW3Ir",
        "outputId": "bf78ce41-caf1-4a99-cb4c-dbd74f6ef7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "|class   |text                                                                                                           |length|\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "|positive|Wow... Loved this place.                                                                                       |24    |\n",
            "|negative|Crust is not good.                                                                                             |18    |\n",
            "|negative|Not tasty and the texture was just nasty.                                                                      |41    |\n",
            "|positive|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |87    |\n",
            "|positive|The selection on the menu was great and so were the prices.                                                    |59    |\n",
            "|negative|Now I am getting angry and I want my damn pho.                                                                 |46    |\n",
            "|negative|Honeslty it didn't taste THAT fresh.)                                                                          |37    |\n",
            "|negative|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|111   |\n",
            "|positive|The fries were great too.                                                                                      |25    |\n",
            "|positive|A great touch.                                                                                                 |14    |\n",
            "|positive|Service was very prompt.                                                                                       |24    |\n",
            "|negative|Would not go back.                                                                                             |18    |\n",
            "|negative|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |99    |\n",
            "|positive|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |59    |\n",
            "|negative|I was disgusted because I was pretty sure that was human hair.                                                 |62    |\n",
            "|negative|I was shocked because no signs indicate cash only.                                                             |50    |\n",
            "|positive|Highly recommended.                                                                                            |19    |\n",
            "|negative|Waitress was a little slow in service.                                                                         |38    |\n",
            "|negative|This place is not worth your time, let alone Vegas.                                                            |51    |\n",
            "|negative|did not like at all.                                                                                           |20    |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create all the transformations to be applied in our pipeline. The `StringIndexer` encodes a string column to a column of table indexes. Here we are working with positive and negative game reviews, which will be converted to 0 and 1. This will form our labels, which we'll delve into in the ML unit. The label is what we're trying to predict: will the review's given text let us know if it was positive or negative?"
      ],
      "metadata": {
        "id": "xfO90_yrfvnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create all features for the dataset\n",
        "pos_neg_to_num = StringIndexer(inputCol='class', outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol='token_text')\n",
        "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol=\"hash_token\")\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ],
      "metadata": {
        "id": "MHyPEUXOfKQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create a feature vector containing the output from the IDFModel (the last stage in the pipeline) and the length. This will combine all the raw features to train the ML model that we'll be using. "
      ],
      "metadata": {
        "id": "BFT_UHaAhjkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "#create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "metadata": {
        "id": "TAMr5ASIhjIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to create our pipeline, the easiest step. We'll import the pipeline from `pyspark.ml`, and then store a list of the stages created earlier. It's important to list the stages in the order they need to be executed. As we mentioned before, the output from one stage will then be passed off to another stage."
      ],
      "metadata": {
        "id": "69AVad3DhHmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating and running the data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "metadata": {
        "id": "SbbFVJQKf_dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit our original df and transform it \n",
        "cleaner = data_prep_pipeline.fit(dataDF)\n",
        "cleaned = cleaner.transform(dataDF)"
      ],
      "metadata": {
        "id": "DgqDfUYkh8mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned.select(['label', 'features']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvZZd-_9iK8a",
        "outputId": "7f0c583d-4a34-405d-d3b7-0236a585252f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|(262145,[177414,2...|\n",
            "|  0.0|(262145,[49815,23...|\n",
            "|  0.0|(262145,[109649,1...|\n",
            "|  1.0|(262145,[53101,68...|\n",
            "|  1.0|(262145,[15370,77...|\n",
            "|  0.0|(262145,[98142,13...|\n",
            "|  0.0|(262145,[59172,22...|\n",
            "|  0.0|(262145,[63420,85...|\n",
            "|  1.0|(262145,[53777,17...|\n",
            "|  1.0|(262145,[221827,2...|\n",
            "|  1.0|(262145,[43756,22...|\n",
            "|  0.0|(262145,[127310,1...|\n",
            "|  0.0|(262145,[407,3153...|\n",
            "|  1.0|(262145,[18098,93...|\n",
            "|  0.0|(262145,[23071,12...|\n",
            "|  0.0|(262145,[129941,1...|\n",
            "|  1.0|(262145,[19633,21...|\n",
            "|  0.0|(262145,[27707,65...|\n",
            "|  0.0|(262145,[20891,27...|\n",
            "|  0.0|(262145,[8287,208...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training/testing by convention it's 70/30% with an arbitrary seed of 21\n",
        "training,testing = cleaned.randomSplit([0.7,0.3], 21)\n"
      ],
      "metadata": {
        "id": "q102Q4bIjkwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "#create naive bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor=nb.fit(training)"
      ],
      "metadata": {
        "id": "1WLOwqfAr82j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform model with testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p38tz0YCsIAm",
        "outputId": "c9554177-45aa-4f22-c592-26daa51909e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"The burger... I ...|    86|  0.0|[\"the, burger...,...|[\"the, burger...,...|(262144,[20298,21...|(262144,[20298,21...|(262145,[20298,21...|[-820.60780566975...|[0.99999999999995...|       0.0|\n",
            "|negative|              #NAME?|     6|  0.0|            [#name?]|            [#name?]|(262144,[197050],...|(262144,[197050],...|(262145,[197050,2...|[-73.489435340867...|[0.07515735596910...|       1.0|\n",
            "|negative|After I pulled up...|    83|  0.0|[after, i, pulled...|[pulled, car, wai...|(262144,[65645,71...|(262144,[65645,71...|(262145,[65645,71...|[-620.40646705112...|[1.0,1.9205984091...|       0.0|\n",
            "|negative|Also, I feel like...|    58|  0.0|[also,, i, feel, ...|[also,, feel, lik...|(262144,[61899,66...|(262144,[61899,66...|(262145,[61899,66...|[-528.59562125515...|[0.99999999994873...|       0.0|\n",
            "|negative|Anyway, I do not ...|    44|  0.0|[anyway,, i, do, ...|[anyway,, think, ...|(262144,[132270,1...|(262144,[132270,1...|(262145,[132270,1...|[-334.09599709326...|[0.99999999994185...|       0.0|\n",
            "|negative|Anyways, The food...|   102|  0.0|[anyways,, the, f...|[anyways,, food, ...|(262144,[6346,685...|(262144,[6346,685...|(262145,[6346,685...|[-779.27125246078...|[0.99905255158977...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 6 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prediction column will indicate with a 1.0 if the model thinks this review is negative and 0.0 if it thinks it's positive. Future data sets can now be run with this model and determine whether a review was positive or negative without having already supplied in the data.\n",
        "\n",
        "How useful is this model? Should we just blindly trust that it will be right every time? There is one last step in the process to answer these questions.\n",
        "\n",
        "It's often not enough to simply train and use a machine learning model for predictions without knowing how well the model performs at its prediction task. The last step is to import the BinaryClassificationEvaluator, which will display how accurate our model is in determining if a review with be positive or negative based solely on the text within a review.\n",
        "\n",
        "The BinaryClassificationEvaluator uses two arguments, labelCol and rawPredictionCol. The labelCol takes the labels which were the result of using StringIndexer to convert our positive and negative strings to integers. The rawPredictionCol takes in numerical predictions from the output of running the Naive Bayes model.\n",
        "\n",
        "The performance of a model can be measured based on the difference between its predicted values and actual values. This is what the BinaryClassificationEvaluator does. We will dive more into accuracy, precision, and sensitivity when we get to Machine Learning."
      ],
      "metadata": {
        "id": "2qInOTzEvTAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to evaluate the veracity of the predictions, we import an evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "acc_eval = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction')\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(f\"Accuracy of model at predicting review was: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmIpxTk6ugyh",
        "outputId": "8143cbbf-425d-410e-f665-32117e7e37d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting review was: 0.7002978406552495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CPOeMQMuvhV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}