{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TokenizeDataPractice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3L_S7CS5GxM",
        "outputId": "1dcdd1d7-ba90-43a3-a6e1-e7eed3877e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [90.7 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [903 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,937 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,089 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,100 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,533 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,310 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,141 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,070 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n",
            "Get:24 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n",
            "Fetched 16.9 MB in 5s (3,161 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.3.0'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "spark=SparkSession.builder.appName(\"Tokenize Data\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "ncE8HmWM5oxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize sentences\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtVYqtHW5pgC",
        "outputId": "933ba8e2-ca0a-4d82-9df4-c78bf84c49c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_65b4e0e330c0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test dataframe\n",
        "df = spark.createDataFrame([\n",
        "    (0, \"hello world\"),\n",
        "    (1, \"greetings, earth\"),\n",
        "    (2, \"waddup, third rock from the sun\")\n",
        "], [\"id\", \"sentence\"])"
      ],
      "metadata": {
        "id": "myKL3cIq6o_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toked_df = tokenizer.transform(df)\n",
        "toked_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SG8QJGe7BGX",
        "outputId": "701a8862-2a90-4d59-be06-3e0da3fa60ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------+--------------------------------------+\n",
            "|id |sentence                       |words                                 |\n",
            "+---+-------------------------------+--------------------------------------+\n",
            "|0  |hello world                    |[hello, world]                        |\n",
            "|1  |greetings, earth               |[greetings,, earth]                   |\n",
            "|2  |waddup, third rock from the sun|[waddup,, third, rock, from, the, sun]|\n",
            "+---+-------------------------------+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to return the length of a list\n",
        "def word_list_length(word_list):\n",
        "  return len(word_list)"
      ],
      "metadata": {
        "id": "5GU32QFo7K_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to employ udf defined above import these spark libraries\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "D53hUYd97unW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a user defined function\n",
        "count_tokens = udf(word_list_length, IntegerType())"
      ],
      "metadata": {
        "id": "9Xl1VPt474aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can redo the `tokenizer` process. Only this time, after the DataFrame has outputted the tokenized values, we can use our own created function to return the number of tokens created. This will give us another data point to use in the future, if needed."
      ],
      "metadata": {
        "id": "oznxGOtK8LJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create tokenizer\n",
        "tokenizer=Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "\n",
        "#transform df\n",
        "toked_df = tokenizer.transform(df)\n",
        "\n",
        "#select needed columns and don't truncate results\n",
        "toked_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3sAaDtl8Ql5",
        "outputId": "01b53ea0-4a7d-4751-d7e8-9d14672f1264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------------------+--------------------------------------+------+\n",
            "|id |sentence                       |words                                 |tokens|\n",
            "+---+-------------------------------+--------------------------------------+------+\n",
            "|0  |hello world                    |[hello, world]                        |2     |\n",
            "|1  |greetings, earth               |[greetings,, earth]                   |2     |\n",
            "|2  |waddup, third rock from the sun|[waddup,, third, rock, from, the, sun]|6     |\n",
            "+---+-------------------------------+--------------------------------------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}